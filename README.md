# ML_interpretation_ensembling_for_strctued_data
The purpose of this repositiry is to illustrate some methods of interpreting the Machine Learning models 
(many times also called as Black Box models) for their so called 'Lack of Interpretability. 
I will also show a few methods of ensemling various models to achieve better results than any single model.

Important: The plots related to SHAP value will not render by default when viewed directly under GitHub.
Please use the extrenal view with nbviewer to see all the graphs properly.
